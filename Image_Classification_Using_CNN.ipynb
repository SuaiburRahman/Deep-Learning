{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf57cd5-b910-4569-b744-e20a3dedc188",
   "metadata": {},
   "source": [
    "Cats & Dogs Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82efcdb4-c6f7-4c93-a6b9-5ae4c30b09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import tkinter\n",
    "from IPython.display import Image\n",
    "from tkinter import Tk, Label, Canvas, Entry, Button, NW\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageTk\n",
    "from tensorflow.keras.models import Sequential,load_model \n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Activation\n",
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img,img_to_array\n",
    "img_width, img_height = 128,128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a6f17c-9ab8-4ace-b50a-630da5cf4c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = 'dataset/training_set'\n",
    "test_data = 'dataset/test_set'\n",
    "nb_train_samples =400\n",
    "nb_test_samples = 200\n",
    "epochs = 10\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ada0a0-4f17-4eb8-af7b-2c0cdfbd307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3), input_shape=(128,128,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        \n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(2,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1141a006-186e-413c-983d-69576b45f5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493ab36-ef3b-4ae6-9b2a-6d20f6accd46",
   "metadata": {},
   "source": [
    "DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4360dd-0608-4349-b488-395dab2df2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 808 images belonging to 2 classes.\n",
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_Datagen=ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True)\n",
    "\n",
    "test_Dategen=ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "training_dataset=train_Datagen.flow_from_directory(train_data,target_size=(img_width,img_height), batch_size=batch_size,class_mode=\"categorical\")\n",
    "testing_dataset=test_Dategen.flow_from_directory(test_data,target_size=(img_width,img_height), batch_size=batch_size,class_mode=\"categorical\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46724e06-2e7a-4ba6-a544-7f39f5926734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 4s 341ms/step - loss: 0.8151 - accuracy: 0.4889 - val_loss: 0.6930 - val_accuracy: 0.5104\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 4s 347ms/step - loss: 0.6910 - accuracy: 0.5361 - val_loss: 0.6927 - val_accuracy: 0.4896\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 5s 372ms/step - loss: 0.6939 - accuracy: 0.5026 - val_loss: 0.6954 - val_accuracy: 0.4740\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 4s 388ms/step - loss: 0.6929 - accuracy: 0.5167 - val_loss: 0.6912 - val_accuracy: 0.5052\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 5s 393ms/step - loss: 0.6939 - accuracy: 0.5208 - val_loss: 0.6854 - val_accuracy: 0.5938\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 5s 424ms/step - loss: 0.6927 - accuracy: 0.5312 - val_loss: 0.6886 - val_accuracy: 0.5312\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 5s 426ms/step - loss: 0.6863 - accuracy: 0.5573 - val_loss: 0.6831 - val_accuracy: 0.5417\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 5s 414ms/step - loss: 0.6784 - accuracy: 0.5677 - val_loss: 0.7087 - val_accuracy: 0.5312\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 5s 415ms/step - loss: 0.6828 - accuracy: 0.5573 - val_loss: 0.6890 - val_accuracy: 0.5417\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 5s 419ms/step - loss: 0.6801 - accuracy: 0.5677 - val_loss: 0.6646 - val_accuracy: 0.6042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c87ff8eac8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_dataset, steps_per_epoch= nb_train_samples//batch_size, epochs=epochs,validation_data=testing_dataset,validation_steps=nb_test_samples//batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db254684-ecbc-426d-84ec-c749abb3cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/model.h5\")\n",
    "model.save_weights(\"model/model_weights.h5\")\n",
    "\n",
    "model_path=\"model/model.h5\"\n",
    "model_weith_path=\"model/model_weights.h5\"\n",
    "\n",
    "final_model=load_model(model_path)\n",
    "final_model.load_weights(model_weith_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e41b470e-67c9-462a-bd5e-1288c7c40ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dot_img_file=\"dataset\\training_set\\cats\\cat.1.JPG\"\n",
    "tf.keras.utils.plot_model(final_model,to_file=dot_img_file,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a52d2f6-2437-494a-b045-9dab51422111",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=''\n",
    "window=tkinter.Tk()\n",
    "window.title(\"Image Classification using CNN\")\n",
    "window.geometry(\"800x800\")\n",
    "label=tkinter.Label(window, text=\"Please enter your custom url\", font=(\"Halvetica\",16))\n",
    "label.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc329c0-cb71-44b2-8692-aac913386b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enter():\n",
    "    global url\n",
    "    label.configure()#why\n",
    "    url=(User_input.get())\n",
    "    print(url)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    test_image=Image.open(BytesIO(response.content))\n",
    "    put_image=test_image.resize((400,400))#source image\n",
    "    test_image=test_image.resize((128,128))\n",
    "\n",
    "    img = ImageTk.PhotoImage(put_image)\n",
    "    pic = Label(image=img)\n",
    "    pic.pack()# merge the image\n",
    "\n",
    "    pic.image=img\n",
    "    test_image=image_utils.img_to_array(test_image)\n",
    "    test_image= np.expand_dims(test_image,axis=0)\n",
    "\n",
    "    results= final_model.predict_on_batch(test_image)\n",
    "\n",
    "    if results[0][0]==1:\n",
    "        res=\"Dogs\"\n",
    "    elif results[0][1]==1:\n",
    "        res=\"Cats\"\n",
    "\n",
    "    output= Label(window,text= \"Predicted Results:\"+res,font=(\"Halvetica\",16))\n",
    "    output.pack()\n",
    "    #window.mainloop()\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159910a-9f5d-4a76-b56f-3dfe10787f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/commons/a/a3/June_odd-eyed-cat.jpg\n",
      "Cats\n"
     ]
    }
   ],
   "source": [
    "User_input=Entry()\n",
    "User_input.pack()\n",
    "button=Button(window,text=\"Detect Image\",font=(\"Halvetica\",16),command=Enter)\n",
    "button.pack()\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
